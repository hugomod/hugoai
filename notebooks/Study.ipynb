{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d24e18fc",
   "metadata": {},
   "source": [
    "# Langchain agent v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8ca66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "\n",
    "from langchain.agents import initialize_agent, Tool, tool\n",
    "from langchain.llms import OpenAI, OpenAIChat\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b60cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the LLM\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "#llm = OpenAI(model_name=\"gpt-4\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"Rule_Violation\")\n",
    "def rule_violation_tool(context: str) -> str:\n",
    "    \"\"\"\n",
    "    Identifies which (if any) rules in the context is violated by the last utterance in the context.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=\"\"\"\n",
    "    Below is a conversation context comprising a set of forum rules and a conversation thread defined by a set of utterances by different users. \n",
    "    \\n\\n CONVERSATION CONTEXT: \\n{context}?\")\n",
    "    \\n\\n\n",
    "    Identify which (if any) rules in the conversation context is violated by the last utterance when understood in context of the rest of the conversation thread. Also explain why/how it is a violation\n",
    "    \"\"\")\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    \n",
    "    result = chain.run(context)\n",
    "    \n",
    "    return result\n",
    "\n",
    "@tool(\"Utterance_Selector\")\n",
    "def utterance_selector_tool(context: str) -> str:\n",
    "    \"\"\"\n",
    "    Identifies the last utterance in the conversation context\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=\"\"\"\n",
    "    Below is a conversation context comprising a set of forum rules and a conversation thread defined by a set of utterances by different users. \n",
    "    \\n\\n CONVERSATION CONTEXT: \\n{context}?\")\n",
    "    \\n\\n\n",
    "    Identify the last utterance in the conversation context\n",
    "    \"\"\")\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    \n",
    "    result = chain.run(context)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "@tool(\"Rule_Exemplification\")\n",
    "def rule_exemplification_tool(context: str) -> str:\n",
    "    \"\"\"\n",
    "    Identifies which (if any) rules in the context is exemplified by the last utterance in the context.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=\"\"\"\n",
    "    Below is a conversation context comprising a set of forum rules and a conversation thread defined by a set of utterances by different users. \n",
    "    \\n\\n CONVERSATION CONTEXT: \\n{context}?\")\n",
    "    \\n\\n\n",
    "    Identify which (if any) rules in the conversation context is exemplified (in a positive prosocial way) by the last utterance when understood in context of the rest of the conversation thread. Also explain why/how it exemplifies\n",
    "    \"\"\")\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    \n",
    "    result = chain.run(context)\n",
    "    \n",
    "    return result\n",
    "\n",
    "@tool(\"Rule_Checker\")\n",
    "def rule_checker_tool(context: str) -> str:\n",
    "    \"\"\"\n",
    "    Checks if the selected last utterance in the conversation context violates (in a bad way) or exemplifies (in a good way) the forum rules. \n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=\"\"\"\n",
    "    Below is a conversation context comprising a set of forum rules and a conversation thread defined by a set of utterances (oldest first, newest last) by different users. \n",
    "    \\n\\n CONVERSATION CONTEXT: \\n{context}?\")\n",
    "    \\n\\n\n",
    "    Identify which (if any) rules in the utterance is exemplified (in a positive prosocial way) or violated (in a negative antisocial way) by the selected utterance when understood in context of the rest of the conversation thread. Also explain why/how it exemplifies or violates\n",
    "    \"\"\")\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    \n",
    "    result = chain.run(context)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "@tool(\"Responder\")\n",
    "def responder(context: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a response to a selected utterance if and when it has either violated or exemplified a forum rule.\n",
    "    \"\"\"\n",
    "    print(\"Responder Input: \", context )\n",
    "    prompt = PromptTemplate(\n",
    "    input_variables=['context'],\n",
    "    template=\"\"\"\n",
    "    Below is a conversation context comprising a set of forum rules and a conversation thread defined by a set of utterances by different users. \n",
    "    \\n\\n CONVERSATION CONTEXT: \\n{context}?\")\n",
    "    \\n\\n\n",
    "    Generate a response to a selected utterance either rewarding the user for a rule exemplifying utterance or warning the user of a forum violation whichever is applicable to the utterance.\n",
    "    Also, your response should match the linguistic style of the selected utterance\n",
    "    \"\"\")\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    \n",
    "    result = chain.run(context)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f91f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [utterance_selector_tool, rule_checker_tool, responder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caae854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set up a custom Agent\n",
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebd10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"You are an online chatroom participant who promotes prosocial behavior by responding to comments. \n",
    "Respond ONLY to the last comment in the conversation thread as best you can. Respond only AFTER you have finished analyzing the last comment in the conversation. \n",
    "\n",
    "You have access to the following tools for analyzing the last comment:\"\"\"\n",
    "\n",
    "format_instructions = \"\"\"Use the following format:\n",
    "\n",
    "Context: the input conversational context containing all the comments including the last comment you must generate a response to\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action, should also include the entire input context\n",
    "Observation: the result of the action\n",
    "... (this above Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now have a response. \n",
    "Final Answer: the final response to the input conversation context\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "Begin! Again, remember to analyze the very last comment in the input context first, before responding to it. And respond ONLY to the last comment, not any others. \n",
    "\n",
    "\n",
    "Context: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools, \n",
    "    prefix=prefix, \n",
    "    suffix=suffix, \n",
    "    format_instructions=format_instructions,\n",
    "    input_variables=[\"input\", \"agent_scratchpad\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace805c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a88ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754240c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ce9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97d95828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE DATA\n",
    "\n",
    "thread = \"\"\"\n",
    "USER1: So glad that we have somewhere to go. My mother needs a doctor.\n",
    "USER2: Agreed. I need to bring my son who has injured his leg, if you don’t mind helping us\n",
    "USER5: We need to help each other. Maybe G1 you could coordinate with G2?\n",
    "USER3: I am not going to a mosque. Those people kill animals and eat cows there\n",
    "USER4: These dogs have been flooding our villages\n",
    "USER5: During a crisis like now, God says we should help people\n",
    "USER3: Fuck the fucking muslims\n",
    "USER5: Stop arguing. We need to help each other.\n",
    "\"\"\"\n",
    "\n",
    "thread5 = \"\"\"\n",
    "USER1: So glad that we have somewhere to go. My mother needs a doctor.\n",
    "USER2: Agreed. I need to bring my son who has injured his leg, if you don’t mind helping us\n",
    "USER5: We need to help each other. Maybe G1 you could coordinate with G2?\n",
    "\"\"\"\n",
    "\n",
    "thread3 = \"\"\"\n",
    "USER1: So glad that we have somewhere to go. My mother needs a doctor.\n",
    "USER2: Agreed. I need to bring my son who has injured his leg, if you don’t mind helping us\n",
    "USER5: We need to help each other. Maybe G1 you could coordinate with G2?\n",
    "USER3: I am not going to a mosque. Those people kill animals and eat cows there\n",
    "\"\"\"\n",
    "\n",
    "thread4 = \"\"\"\n",
    "USER1: So glad that we have somewhere to go. My mother needs a doctor.\n",
    "USER2: Agreed. I need to bring my son who has injured his leg, if you don’t mind helping us\n",
    "USER5: We need to help each other. Maybe G1 you could coordinate with G2?\n",
    "USER3: I am not going to a mosque. Those people kill animals and eat cows there\n",
    "USER4: These dogs have been flooding our villages\n",
    "\"\"\"\n",
    "thread5R = \"\"\"\n",
    "USER1: So glad that we have somewhere to go. My mother needs a doctor.\n",
    "USER2: Agreed. I need to bring my son who has injured his leg, if you don’t mind helping us\n",
    "USER5: We need to help each other. Maybe G1 you could coordinate with G2?\n",
    "USER3: I am not going to a mosque. Those people kill animals and eat cows there\n",
    "USER4: These dogs have been flooding our villages\n",
    "USER5: During a crisis like now, God says we should help people\n",
    "\"\"\"\n",
    "\n",
    "thread3R = \"\"\"\n",
    "USER1: So glad that we have somewhere to go. My mother needs a doctor.\n",
    "USER2: Agreed. I need to bring my son who has injured his leg, if you don’t mind helping us\n",
    "USER5: We need to help each other. Maybe G1 you could coordinate with G2?\n",
    "USER3: I am not going to a mosque. Those people kill animals and eat cows there\n",
    "USER4: These dogs have been flooding our villages\n",
    "USER5: During a crisis like now, God says we should help people\n",
    "USER3: Fuck the fucking muslims\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "rules = \"\"\"\n",
    "1. Be friendly, respectful and polite\n",
    "2. Do not use profanity or sexual language and/or images\n",
    "3. No displays of hatred\n",
    "4. Do not post violent content or incite violence\n",
    "5. No political propaganda\n",
    "6. No unfounded accusations or defamation of others\n",
    "7. Follow grammatical rules, correct writing and language\n",
    "8. Cite sources for factual information\n",
    "9. Criticisms should be constructive\n",
    "10. Stay on topic\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "threads = [thread5, thread3, thread4 , thread5R, thread3R]\n",
    "\n",
    "context5 = f\"Rules:\\n {rules} \\n\\n Conversation Thread: {thread5}\"\n",
    "context3 = f\"Rules:\\n {rules} \\n\\n Conversation Thread: {thread3}\"\n",
    "context4 = f\"Rules:\\n {rules} \\n\\n Conversation Thread: {thread4}\"\n",
    "context5R = f\"Rules:\\n {rules} \\n\\n Conversation Thread: {thread5R}\"\n",
    "context3R = f\"Rules:\\n {rules} \\n\\n Conversation Thread: {thread3R}\"\n",
    "\n",
    "contexts = [context5, context3, context4, context5R, context3R]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a3b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(context3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42566d36",
   "metadata": {},
   "source": [
    "# Langchain Agent v2\n",
    "\n",
    "Date: 4/4/2023\n",
    "\n",
    "Doing a simple chain here (not Agent and tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99c18db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "#llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0)\n",
    "llm = OpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2f4cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_id_last_utterance = \"\"\"\n",
    "    Below is a conversation thread defined by a set of utterances by different users. Identify the last utterance in the thread.\n",
    "    \\n\\n \n",
    "    Conversation Thread: {thread}\\n\n",
    "    Last Utterance: \n",
    "    \"\"\"\n",
    "prompt_id_last_utterance = PromptTemplate(\n",
    "    input_variables=[\"thread\"],\n",
    "    template=template_id_last_utterance,\n",
    ")\n",
    "\n",
    "chain_id_last_utterance = LLMChain(llm=llm, prompt=prompt_id_last_utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9aa959",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_utterance_expander = \"\"\"\n",
    "Below is a conversation context comprising a conversation thread and a selected utterance.\n",
    "Elaborate on what the selected utterance actually means in the context of what was already stated in the conversation thread.\n",
    "Specifically, elaborate on all the referring expressions and what they could mean. \n",
    "Focus on explicating if words have negative or positive connotations in this context, and what/who group (mentioned previously in context) they refer to.\n",
    "Remember, words might specific (even unusual) meaning in this particular context, different from other contexts. For example animals and inanimate objects may actually refer to groups or types of people.\n",
    "\n",
    "\\n\\n CONVERSATION CONTEXT: \\n\n",
    "    Thread:\\n{thread}\\n\n",
    "    Selected Utterance: \\n{utterance}\\n\n",
    "    Deeper Meaning of selected utterance:\n",
    "\"\"\"\n",
    "\n",
    "prompt_utterance_expander = PromptTemplate(\n",
    "    input_variables=[\"thread\",\"utterance\"],\n",
    "    template=template_utterance_expander,\n",
    ")\n",
    "\n",
    "chain_utterance_expander = LLMChain(llm=llm, prompt=prompt_utterance_expander)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a83793d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_rule_checker=\"\"\"\n",
    " Below is a conversation context comprising a set of forum rules, a conversation thread, a selected utterance and its deeper meaning. \n",
    " Identify which (if any) rules in the selected utterance is exemplified (in a positive prosocial way) or violated (in a negative antisocial way) by the selected utterance when understood in context of the rest of the conversation thread. Also explain why/how it exemplifies or violates\n",
    "\n",
    "    \\n\\n CONVERSATION CONTEXT: \\n\n",
    "    Rules: \\n{rules}\\n\n",
    "    Conversation thread: \\n{thread}\\n\n",
    "    Selected Utterance: {utterance}\\n\n",
    "    Deeper meaning: {meaning}\\n\n",
    "    Rule exemplifcation/violation: \n",
    "\"\"\"\n",
    "\n",
    "prompt_rule_checker = PromptTemplate(\n",
    "    input_variables=[\"rules\",\"thread\",\"utterance\", \"meaning\"],\n",
    "    template=template_rule_checker,\n",
    ")\n",
    "\n",
    "chain_rule_checker = LLMChain(llm=llm, prompt=prompt_rule_checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c29897cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_dsr=\"\"\"\n",
    "Below is a conversation context comprising a conversation thread, a selected utterance and its deeper meaning.\n",
    "Identify if the user (author) of the selected utterance is targeting \"social regard\" towards a particular group of people.\n",
    "The \"social regard\" could be positive (like empathy, respect, helpfulness) or negative (like contempt, dehumanization, harming).\n",
    "Identify the specific group being targeted as well as the type of social regard directed towards the group.\n",
    "\n",
    "\\n\\n CONVERSATION CONTEXT: \\n\n",
    "    Thread:\\n{thread}\\n\n",
    "    Selected Utterance: \\n{utterance}\\n\n",
    "    Deeper Meaning: \\n{meaning}\\n\n",
    "    Directed Social Regard toward a particular Group of people:\n",
    "\"\"\"\n",
    "\n",
    "prompt_dsr = PromptTemplate(\n",
    "    input_variables=[\"thread\",\"utterance\", \"meaning\"],\n",
    "    template=template_dsr,\n",
    ")\n",
    "\n",
    "chain_dsr = LLMChain(llm=llm, prompt=prompt_dsr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef3bd649",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_respond=\"\"\"\n",
    " Below is a conversation context comprising a set of forum rules, a conversation thread, a selected utterance, its deeper meaning, and an analysis of whether the selected utterance violated or exemplified any rules. \n",
    " Generate a response to a selected utterance either rewarding the user for a rule exemplifying utterance or warning the user of a forum violation whichever is applicable to the utterance.\n",
    " When the user of the selected utterance is displaying negative social regard towards a group, your response must remind the user of what qualities, desires, beliefs, intentions, morals or values they share in common with the targeted group. \n",
    " Your response should address the user of the selected utterance, match the linguistic style of the thread, and must display prosocial qualities of empathy, compassion, and curiosity.\n",
    " Keep your response short (under 50 words)\n",
    "    \n",
    "    \\n\\n CONVERSATION CONTEXT: \\n\n",
    "    Rules:\\n{rules}\\n\n",
    "    Thread:\\n{thread}\\n\n",
    "    Selected Utterance: \\n{utterance}\\n\n",
    "    Deeper Meaning: \\n{meaning}\\n\n",
    "    Directed Social regard towards a group: \\n{dsr}\\n\n",
    "    Analysis: \\n{analysis}\\n\n",
    "    Response:\n",
    "\"\"\"\n",
    "\n",
    "prompt_respond = PromptTemplate(\n",
    "    input_variables=[\"thread\",\"utterance\", \"analysis\", \"rules\", \"dsr\", \"meaning\"],\n",
    "    template=template_respond,\n",
    ")\n",
    "\n",
    "chain_respond = LLMChain(llm=llm, prompt=prompt_respond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "289d9c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "USER4, we are all part of the same community and share the same desire for safety and security. Let's focus on finding solutions that benefit everyone.\n"
     ]
    }
   ],
   "source": [
    "thread = thread4\n",
    "utterance = chain_id_last_utterance.run(thread=thread)\n",
    "meaning = chain_utterance_expander.run(thread=thread, utterance=utterance)\n",
    "analysis = chain_rule_checker.run(rules=rules, thread=thread, utterance=utterance, meaning=meaning)\n",
    "dsr = chain_dsr.run(thread=thread, utterance=utterance, meaning=meaning)\n",
    "response = chain_respond.run(rules=rules, thread=thread, utterance=utterance, analysis=analysis, dsr=dsr, meaning=meaning)\n",
    "print(\"\\n\",response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9be8afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85923339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044281ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "438.857px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
